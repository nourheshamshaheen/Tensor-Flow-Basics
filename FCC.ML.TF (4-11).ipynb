{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41a70a8",
   "metadata": {},
   "source": [
    "# CORE LEARNING ALGORITHMS\n",
    "\n",
    "## 1- Linear Regression:\n",
    "\n",
    "The next example is a model predicting the survival rate of titanic passengers using certain features, via linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4473c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7dd401",
   "metadata": {},
   "source": [
    "### Working with pandas' dataframes\n",
    "\n",
    "\n",
    "**Some notes**:\n",
    "- \".csv\": stands for comma separated values\n",
    "- We will choose \"survived\" column to be our label (value we are trying to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ec4de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf\n",
    "\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "\n",
    "\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2523f",
   "metadata": {},
   "source": [
    "### Some functions dealing with dataframes:\n",
    "\n",
    "**pd.read_csv('csv_file_name'):** returns a pandas dataframe (sth like a table)\n",
    "\n",
    "**df.head():** returns first five rows from the dataframe\n",
    "\n",
    "**df.pop('column_name'):** returns and deletes column w/ name \"column_name\"\n",
    "\n",
    "**df.loc\\[i\\]:** returns row with index i\n",
    "\n",
    "**df.describe():** returns some basic info abt dataframe\n",
    "\n",
    "**df.shape():** returns table shape\n",
    "\n",
    "**df.feature.hist(bins=i):** displays histogram of column \"feature\" w/ i as the number of bins.\n",
    "\n",
    "*Note*: display some charts abt your data so you can get some sort of intuition as to what the label may point to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c606c",
   "metadata": {},
   "source": [
    "### Important Notes:\n",
    "\n",
    "- Separate data sets into training set and testing set.\n",
    "\n",
    "- **Categorical Data:** Data that is made up of categories (i.e Male, Female, Other). Dealing w/ it is through **one hot encoding**.\n",
    "\n",
    "#### One hot encoding:\n",
    "Every category is a feature and we determine which category by using 1 for the correct category for the entry and 0's otherwise.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d7e854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "#print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2ec82",
   "metadata": {},
   "source": [
    "### Training process:\n",
    "\n",
    "- Data is streamed into batches, we don't add entire dataset to model at once\n",
    "- These batches can be fed to the model multiple times according to the number of epochs\n",
    "\n",
    "**Epochs:** one stream of the entire dataset, # of epochs is # of times the model will see the entire dataset.\n",
    "\n",
    "**Overfitting:** memorizing data points in training set only, not able to classify new elements.\n",
    "\n",
    "**Underfitting:** opposite of overfitting, not being able to predict.\n",
    "\n",
    "\n",
    "A tensorflow model requires the data we pass to it to be in the form of ```tf.data.Dataset``` object. So, we create an *input function* to convert a pandas dataframe to a tf Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13a181fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "  def input_function():  # inner function, this will be returned\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)  # randomize order of data\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "    return ds  # return a batch of the dataset\n",
    "  return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec427e2c",
   "metadata": {},
   "source": [
    "Above is a standard input function copied from tensorflow value.\n",
    "\n",
    "*Notes*: in evaluation, num_epochs=1 and shuffle=False\n",
    "\n",
    "\n",
    "\n",
    "### Creating, Training, Testing and Predicting\n",
    "\n",
    "**Creating:** to create a model we need to create an *estimator*, there is one for every core learning algorithm.\n",
    "\n",
    "Since we're using linear regression: we will use an estimator of type LinearClassifier that takes the feature_columns created before.\n",
    "\n",
    "**Training & testing:** training & testing the model is done by passing the input functions created.\n",
    "\n",
    "**Predicting:** predicting is entering an input_function and getting the probability of label 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5f9a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "\n",
    "clear_output()\n",
    "# We create a linear estimtor by passing the feature columns we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3792d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7537879\n"
     ]
    }
   ],
   "source": [
    "linear_est.train(train_input_fn)  # train\n",
    "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n",
    "\n",
    "clear_output()  # clears console output\n",
    "print(result['accuracy'])  # the result variable is simply a dict of stats about our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fa5c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\NOURHE~1\\AppData\\Local\\Temp\\tmpt0wzfmbg\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "result_dicts = list(linear_est.predict(eval_input_fn))\n",
    "probs = pd.Series([result['probabilities'][1] for result in result_dicts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b310a1",
   "metadata": {},
   "source": [
    "## Molakhas - Linear Regression: \n",
    "\n",
    "- Read csv files and put them into pandas dataframes\n",
    "- Do one-hot encoding on categorical data: outputting *feature_columns*\n",
    "- Make *input function* transforming dataframe to a tf Dataset \n",
    "- Create LinearClassifier estimator using feature_columns dataframe as input\n",
    "- Train estimator: ```est.train(train_input_fn)```\n",
    "- Evaluate estimator (test it) & return result: ```est.evaluate(eval_input_fn)```\n",
    "- result\\['accuracy'\\]: shows accuracy of model\n",
    "- To predict: ```est.predict(input_fn)```, returns result, we can transform result to list\n",
    "- If we print one item of the list result: we can see percentage of survival (probability of label)\n",
    "- ```print(result[0]['probabilities'][1])``` <-- Probability that passenger survives.\n",
    "\n",
    "\n",
    "\n",
    "**Notes**: changing # of epochs changes accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdbd506",
   "metadata": {},
   "source": [
    "## 2- Classification\n",
    "\n",
    "Classification is used to seperate data points into classes of different labels. The next example is classifying flowers into one of three types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de31bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366adcd1",
   "metadata": {},
   "source": [
    "Previously, we just set constants for flower features and flower species (labels).\n",
    "\n",
    "Dataset used is \"iris\" dataset. Here, we are importing csv files through Keras and storing them into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5e2a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db89d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fdaa981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd79f0e",
   "metadata": {},
   "source": [
    "Here, the label is the \"species\" column. Thus, we have 120 data entry.\n",
    "\n",
    "Then, we should pop the species column and use it as a label.\n",
    "\n",
    "Next, after getting our data & labels, we make an input function (slightly different than before). This input function doesn't have any epochs. But it does the same thing as before: convert a pandas dataframe into a tf.data.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "040a9522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head() # the species column is now gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a515616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode\n",
    "    # Another way of saying: shuffle=True\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c9b7447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb045e3",
   "metadata": {},
   "source": [
    "We don't need to do the vocabulary thing because everything is one hot encoded (no categorical data, all numeric).\n",
    "\n",
    "**train.keys():** is the same as feature_name, each key is a feature column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f6ceb",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "For classification tasks there are variety of different estimators/models that we can pick from:\n",
    "\n",
    "- DNNClassifier (Deep Neural Network) - *better*\n",
    "- LinearClassifier\n",
    "\n",
    "Why is DNNClassifier better? Because we may not be able to find a linear correspondence in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f596d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each (arbitrary #).\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    hidden_units=[30, 10],\n",
    "    n_classes=3)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5afcf8",
   "metadata": {},
   "source": [
    "### DNN Classifier Use:\n",
    "\n",
    "DNN Classifier takes 3 inputs: feature_columns, a list of hidden units and number of classes to classify data into.\n",
    "\n",
    "**Hidden units list:** number of elements is number of hidden layers and each element's value is the number of nodes in that layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449565cf",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "- To avoid creating an inner function (like in linear regression) we use lambda:\n",
    "\n",
    "```variable = lambda *arguments* : *expression*```\n",
    "\n",
    "- The steps operator is how many times the classifier to run for. Similar to epochs, but instead of running through the data set a # of times, classifier stops after looking at steps number of \"things\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fc98157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = lambda a: a+10\n",
    "x(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8e0bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We include a lambda to avoid creating an inner function previously\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca7f6e",
   "metadata": {},
   "source": [
    "### Evaluating model (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf299eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "clear_output()\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b04523",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e858a4",
   "metadata": {},
   "source": [
    "**class_ids:** class_id is label index of found (classified) entry in array of constants\n",
    "\n",
    "**probabilities**: returns 3 probabilities for each class.\n",
    "\n",
    "**pred_dict\\['probabilities'\\]\\['class_ids'\\]:** prints out class name with highest probability of the 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de1f5208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "SepalLength: 2.3\n",
      "SepalWidth: 2.3\n",
      "PetalLength: 2.3\n",
      "PetalWidth: 2.3\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\NOURHE~1\\AppData\\Local\\Temp\\tmpcabkgcd_\\model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Virginica\" (90.7%)\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "  valid = True\n",
    "  while valid: \n",
    "    val = input(feature + \": \")\n",
    "    if not val.isdigit(): valid = False\n",
    "\n",
    "  predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a0d2bb",
   "metadata": {},
   "source": [
    "## Molakhas Classification:\n",
    "\n",
    "- Load data into pandas dataframe\n",
    "- Create feature_columns for numeric keys\n",
    "- Specify input function: steps, shuffle, ...etc.\n",
    "- Create DNNClassifier estimator w/ inputs: feature_columns and input fn\n",
    "- classifier.train\n",
    "- classifier.evaluate\n",
    "- If you want to predict unknown values: classifier.predict **but** w/ different input function w/ no labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c88f5e",
   "metadata": {},
   "source": [
    "## 3- Clustering: Unsupervised Learning\n",
    "\n",
    "No labels, no output, just input and find n clusters.\n",
    "\n",
    "**Centroid**: where different clusters currently exist\n",
    "\n",
    "\n",
    "### K-Means Algorithm:\n",
    "\n",
    "1. Choose K points to place K centroids.\n",
    "2. Each point is assigned to the closest centroid by distance.\n",
    "3. Move centroids to center of mass of points that are assigned to it.\n",
    "4. Repeat assignment step.\n",
    "5. Repeat last two steps until none of the points are moving anymore (until centroids are directly in the middle of clusters of data).\n",
    "\n",
    "To predict:\n",
    "1. Plot that data point\n",
    "2. Find distance to all clusters.\n",
    "3. Output is label of closest cluster.\n",
    "\n",
    "Note: You need to define variable K (number of clusters).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c9bb5",
   "metadata": {},
   "source": [
    "## 4- Hidden Markov Models: Unsupervised Learning\n",
    "\n",
    "We deal w/ probability distributions. The example used is weather forecasting given the probabilities of certain events occuring.\n",
    "\n",
    "We have a bunch of states (i.e hot day, cold day).\n",
    "\n",
    "In each state, we have an observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a9557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
